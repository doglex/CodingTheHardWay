[TOC]

### 操作系统
是指控制和管理整个计算机系统的**硬件**和**软件**资源，<br>
并合理地组织**调度**计算机的工作和资源的分配，<br>
以提供给用户和其他软件方便的**接口**和**环境**，<br>
是计算机系统中最基本的**系统软件**。

### 操作系统的功能和目标

1. 作为系统资源的管理者<br>
功能:
    + 处理机管理
    + 存储器管理
    + 文件管理
    + 设备管理<br>
目标:高效、安全
2. 作为用户和硬件直接的接口<br>
功能：命令接口(联机命令逐个做，脱机命令做一批)、程序接口(比如dll)、GUI (Graphical User Interface) 
> 命令接口是说直接调用；`程序接口`是说可以`间接使用`，当然是由一堆`系统调用`组成的 😳<br> 
> `系统调用` = `广义指令` 😪

3.对硬件扩展

### 操作系统四大特征
`并发`和`共享`(两个基本，互为条件)， `虚拟`, `异步`
> 并发(concurrency)：多个事件在同一时间`间隔`发生。宏观上(逻辑上)同时发生，微观上(物理上)交错发生 <br>
> 并行(parallelism)：多个时间在同一时间`同时`（物理上）发生。 `那是说要多核了啊，对一个核而言只处理一件事`🤣

+ `并发`：允许多个程序在(交替或并行)运行，即`多道程序技术` 
+ `共享`：互斥共享(独占资源)、(宏观上)同时共享 
+ `虚拟`：物理实体对应到逻辑实体： 比如空分复用(虚拟内存)、时分复用(虚拟CPU搞并发)
+ `异步`：有多个程序并发的时候，对于程序的小片段相对另一个程序来说执行顺序不可预先确定。可以阻塞、可以释放

> 因为业务上有太多时间容忍度很小的事件。事件驱动

### 操作系统的历史
+ 手工操作阶段：纸带机, 用户独占全机、人机速度矛盾导致资源利用率低
+ 单道批处理阶段： 磁盘机+外围机，脱机输入输出，`监督程序`（操作系统雏形）控制I/O :只能串行、大量IO阻塞
+ 多道批处理阶段：交替执行，引入`中断`功能(IO与计算之间可以不相互阻塞了，设备间并行了)，`操作系统诞生`😥。：虽然能并发，但是没法人机`交互`，你要等他这个程序跑完或报错
+ 分时操作系统：时间片轮流服务，那么轮到你的时间片的时候就可以`交互`了，你可以告诉他我这个程序要关掉：但是时间片是公平的，不能`优先处理紧急任务`
+ 实时操作系统：`紧急任务`的时间片可以"插队"，更加及时可靠。比如导弹的硬实时系统、而软实时系统的紧急事件等一等也没事
+ 网络操作系统、分布式操作系统、个人计算机操作系统



### 操作系统运行机制和架构

> `指令` 和`代码`的区别？ C语言代码可能翻译成多条机器语言 (二进制)指令，可以被CPU 具体识别。
+ 特权指令：不允许用户程序使用。比如内存清零指令、访问硬件等。
+ 非特权指令：比如普通的运算。

> PSW(程序状态字寄存器)中某个标志位表示CPU状态。
+ CPU处于`用户态`时只能执行非特权指令。
+ CPU处于`核心态`时都可以执行。

> (普通)`应用程序`为了安全，只能用非特权指令。 比如记事本、任务管理器，不是内核功能。

> `内核`(内核程序) 可以执行两种指令，运行在核心态。因此，用了核心态的功能的程序就是内核程序。 比如时钟管理、原语程序(具有原子性，即要么执行要么不执行)、中断处理程序。

> 有的操作系统把进程管理、存储器管理、设备管理也算内核。(如果算，就称为`宏内核`， 否则就是`微内核`)

> `宏内核`：代码庞大、性能高；`微内核`：代码少，需要频繁在核心态和用户态之间切换。


### (外)中断和(内中断)异常
> 解决资源串行利用率低的问题。需要中断来并发执行。

> CPU收到计时部件的`中断信号`，（立刻）切换为`核心态`,让操作系统介入管理,操作系统会对不同的信号做不同处理。

> 从用户态→核心态只能通过中断实现。而核心态→用户态只需要改PSW。

> 外中断：外设请求、人工干预。(信号来自CPU外部)

> 内中断(异常、例外、陷入)：自愿中断(指令中断)，强迫中断(硬件故障，比如缺页、软件中断，比如除0)。


### 系统调用
> 为什么提供系统调用？ 避免每个进程随意使用资源、需要OS进行协调管理一些公共的函数， 保证稳定性和安全性。
一般需要特权指令、在核心态下完成

+ 设备：请求/释放/启动
+ 文件：读/写/创建/删除
+ 进程: 创建/撤销/阻塞/唤醒/信号传递/信息传递
+ 内存: 分配/回收


### 进程

程序：一个指令序列。<br>
`进程`(Process):`资源分配的基本单元`， 被CPU调度的单元，就是程序的一次执行。 `进程实体`由程序段、数据段、PCB组成。PCB是进程唯一存在标志。<br>
`线程`(Thread):`CPU调度的基本单元`。 

> PCB(进程控制块):里面会有记各个寄存器的值，下次轮到执行时可以恢复。进程本身是动态的，进程实体里存了静态的数据。

> 操作系统的`执行指针`：指向当前执行的PCB;`就绪表指针`，指向就绪PCB列表；`阻塞表指针`，指向阻塞的PCB列表。

进程特征：
+ 动态性
+ 并发性： 并发结果会不确定。需要操作系统提供`进程同步`来保证。
+ 独立性
+ 异步性
+ 结构性

#### 进程的状态转化

三种基本状态：(看拥有的资源可以知道是什么状态)
+ 运行态(Running)：独占CPU(一个核)
+ 就绪态(Ready):具备运行条件，`只差CPU`
+ 阻塞态(Blocked/Waiting):还差`其他资源/事件`条件，暂时不能运行

两种额外状态：
+ 创建态： 正在分配资源，初始化PCB
+ 终止态： 正在回收资源，销毁PCB

转换：
+ 创建态 → 就绪态 → 运行态
+ 运行态 → 就绪态：时间片到、或被抢占
+ 运行态 → 阻塞态：（主动）“系统调用”等待资源、等待事件
+ 阻塞态 → 就绪态：（被动）资源好了，等待CPU
> 不能阻塞态直接到运行态的，也不能就绪态到阻塞态的 （书上是这么说）

#### 进程控制：就是实现进程状态转换
PCB用于保存/恢复进程环境、记录标志位、排队<br>
用`原语`(即`原子操作`，只能一气呵成，需要运行在`核心态`)实现控制.先`关中断`，完成后`开中断`实现了原子操作，外部中断信号会被临时屏蔽。
<br>原语做三件事：更新PCB、插PCB到合适队列、分配/回收资源。
+ 进程创建(创建原语)：用户登录、作业调度、提供服务、应用请求(子进程)
+ 进程终止(撤销原语):正常结束、异常结束(比如div 0)、外界干预
+ 进程阻塞(阻塞原语)：等待资源(比如IO)、等待其他进程
+ 进程唤醒(唤醒原语): 等待的事件(被阻塞的事件)发生


#### 进程通信：进程间交换信息
进程是分配资源的基本单位，(为了安全)各进程的内存空间独立(不能直接相互访问)
+ `共享存储`：(互斥的访问，操作系统提供PV)共享空间：包括`共享存储结构`、`共享存储区`(速度更快)
+ `管道通信`：基于(互斥的)共享文件，即在内存中开辟缓冲区。管道只能`半双工`(一个时间内单向)。可以做两个管道同时两个方向。
管道满了后write()要等待读进程的read()，空了等write()。没写满不能读，没读空不嫩写。一旦取出就没了，`因此只能被一个进程读`。
+ `消息传递`：通过`格式化的消息`(消息头+消息体)，操作系统提供发送原语/接收原语。直接通信，可以直接挂在接收进程的消息缓重队列。间接通信，需要通过中间的信箱。

### 线程
“线程”增加进程内的并发度，成了`程序执行的最小单元`（`CPU调度基本单位`），进程内可以改变执行流。
+ 线程是CPU调度的单位
+ 各个线程可占用不同CPU
+ 每个线程有线程ID、线程控制块TCB
+ 线程也有就绪、阻塞、运行三种基本状态
+ 线程几乎不拥有系统资源
+ 同一进程的不同线程间共享进程资源(进程是最小资源分配单元)
+ 因为进程内共享内存地址空间，无需OS干预就可以进程内通信
+ 切换进程内的线程系统开销较小(而进程切换开销大)

<br>用户级线程(User-Level Thread, ULT, 即Green Thread)：由应用程序管理，线程切换在`用户态`完成。用户看到是多线程(可以多个同时映射到内核线程上)、操作系统只看到了一个进程。
<br>内核级线程(Kernel-Level Thread, KLT):内核支持管理的线程。操作系统看的到，需要在`内核态`切换。
> `内核级线程`才是CPU调度单位。不然就是用户程序自己调度。
+ 多对一模型：并发度不高，可能会卡在一个用户级线程，因为都去使用内核线程。
+ 一对一模型：单个进程占了多个内核，卡住概率低，要在核心态切换，开销大。
+ 多对多模型：n >= m。比上面两种合理。

### 调度问题
+ 先到先服务
+ VIP优先
+ 时间短优先

<br>(高级调入)作业调度：从作业列表选出作业，由外存调入内存、建立PCB进程。频率低。
<br>(中级调度)内存调度(进入`进程挂起状态`，即挂起队列。阻塞态的进程也可以进挂起)：暂时不能运行的调入虚拟内存(外存)与调回。提高内存利用率和系统吞吐量。
<br>(低级调度)进程调度：频率高，一般几十毫秒。

<br>什么时候需要进程调度？
+ 主动放弃处理机(CPU)
+ 被动放弃：时间片用完、紧急事情、更高优先级进程进入
<br>什么时候不能进程调度或切换？
+ 做中断处理时
+ 在原子操作过程中
+ 进程在操作系统`内核程序临界区`(不是普通临界区)中。
> 临界资源：互斥访问的资源。临界区：访问临界资源的代码。内核临界区：访问某种内核数据结构的代码，比如访问进程的就绪队列。
<br>调度方式
+ `非抢占式`。(非剥夺式)，只能等他自己结束，主动放弃处理机，然后其他任务可能被分配。😪现代OS，那这种东西没用啊
+ `抢占式`。(剥夺式)，紧急任务可以抢用

#### 调度算法的指标
+ CPU利用率(CPU认为是最重要的资源)：忙碌/总时间。
+ 吞吐量：完成作业数/总共时间(秒)。
+ 周转时间：(平均)作业提交开始导作业完成为止的时间间隔。
+ 带权周转时间： (平均)周转时间除以实际运行时间。(本来就是那么多时间，你却花了额外的时间排队、切换)
+ 响应时间：提交请求首次被回应的时间。

#### 调度算法
算法思想、算法规则、是作业调度还是进程调度、是否抢占式、优缺点、是否饥饿(某作业一直不能服务)
> 早期批处理算法：这3种没用，因为用户无法交互，不能设权重。
+ FCFS (First Come First Serve 先来先服务)。
"公平"服务、非抢占、谁先来谁先服务。缺点：对于排在`长作业`后的`短作业` 体验不好，对长作业有利。不会饥饿。
+ SJF (Short Job First 短作业优先)。
多作业/进程优先。可以做抢占式的。优点：短作业有利，长作业不利。可能长作业会饥饿。
+ HRRN (Highest Response Ratio Next)。
综合考虑等待时间和服务时间，响应比高的优先。 响应比= (等待时间+要求服务时间) / 要求服务时间。非抢占的。不会饥饿。
> 后来的算法
+ RR(Round-Robin, 时间片轮转)。公平轮转的让各个进程执行一个CPU时间片(100ms可能，也可能动态的)。是(时钟中断)抢占式的。响应快，但是切换开销大，需要设计好时间片。不会饥饿，但是吃不饱。
+ 优先级调度算法：可以抢占式或者不抢占式。可以实现紧急任务。会饥饿。
+ 多级反馈队列调度算法：综合上面的算法，复杂，多个优先级的队伍，可以降级。一般用于进程调度，可以抢占式的。会饥饿。

### 进程同步/互斥
`同步`：进程需要协调工作次序。
<br>`临界资源`:访问共享的(进程互斥)互斥资源时只能互斥的进行：上锁、临界区、解锁。
<br>进程互斥原则：空闲让进、忙则等待、有限等待、让权等待。
> 进程互斥软件方法：
+ 单标志法：每个进程进入临界区的权限只能被另一个进程赋予， turn=pid_next。同一时刻最多只有一个进程使用临界区，违背“空闲让进”原则。
+ 双标志法：用flag[] 数组表示每个pid是否想进入临界区。那么就知道了别的pid是否想进入了。违背了“忙则等待”原则，而且可能同时上锁。`检查+上锁不能一气呵成`。
+ 双标志后检查法：先上锁，后检查是否有别的pid也来上锁了，才开始访问。可能大家都饥饿。
+ Peterson算法：双标志法+若冲突了让对方先用+单标志表示谁在用，自己循环等待。没符合“让权等待”.
>  进程互斥硬件方法：
+ 中断屏蔽法：开中断、关中断。类似上锁，不让进程切换了。原语也是这样实现的。不适合多处理机。
+ TestAndSetLock(TSL)指令：直接上锁 lock=true，返回lock之前的值。用的人来看要不要用，也是要调用的人来用完解锁。检查和上锁是一次完成的。可以多CPU，不满足“让权等待”。
+ Swap指令(Exchange, XCHG)： 和上面的类似的。
>  信号量机制(1965年Dijkstra提出) 可以实现进程互斥:
操作系统一对(wait(S)/signal(S)， 即PV操作)原语来对信号量(可以是整数变量或者记录型变量)操作。
wait申请资源或者等待、signal释放资源。
```
type struct semaphore {int value //剩余资源; struct process *L ;//等待队列} mutex
```
```
P1 { f1 ; f2 ; V(S); f3}
P2 { P(S); f4; f5 ;f6}
在"Pre"后执行V(S)，在"Post"前执行P(s)，即可以保证进程前后关系。即进程同步。
```
> `管程`--高级进程同步机制(Pascal中引入，java中的`synchronized`)。是一种软件机制，即共享的数据结构只有通过一个管程内特殊的函数修改，由管程来保证一次一个进程。即固定了访问入口，在编译器上实现了互斥。

> `生产者-消费者`模型(Producer-Consumer)

### 死锁 DeadLock
`死锁`：多个进程间等待对方资源，导致相互阻塞，无法推进。
<br>`饥饿`:某进程长时间不能推进。
<br>`死循环`:一直跳不出循环。(有时候是逻辑故意设计的)

死锁产生条件：
+ 互斥条件：进程争抢互斥资源。
+ 不可抢占(剥夺)条件：别人抢不走资源。
+ 请求和保持条件：一直保持了自己的资源，去请求别人的
+ 循环等待条件：资源等待链

死锁发生的场景：
> 即对不可剥夺资源的处理不当
+ 对不可剥夺资源的竞争
+ 进程推进顺序非法(顺序不合理)
+ 信号量使用不当

死锁处理：
+ (静态)预防死锁：破坏死锁条件
+ (动态)避免死锁：比如银行家算法
+ 死锁检测和解除：允许死锁发生，系统负责检测死锁并解除

> 预防死锁
+ 破坏互斥条件：改为可共享的资源，比如SPOOLing技术
+ 破坏不剥夺条件：进程请求新资源时不够就释放已有的资源；或者直接抢其他进程的资源。实现复杂
+ 破坏请求和保持条件：静态分配，一开始就申请完所有资源。但是资源利用率低
+ 破坏循环等待条件：对进程变化，小编号进程可以申请大变化进程资源，反向不行。缺点是不方便新设备

> 避免死锁--银行家算法(Banker's Algorithm)
<br>安全序列：依次分配资源、系统可以按序完成每个进程。
<br>安全状态：至少能找到一个安全序列。不安全状态就是找不到。若进入不安全状态则可能死锁。
<br>进程来申请资源的时候看看给他之后还安全不安全(假设之后可以回收某进程的话，够不够资源流通)，不安全就不给。

> 死锁检测
资源分配图(资源和进程进行连线)分析。是否`可以完全简化`，试试消除边，分析安全不安全。
若干死锁了，就资源剥夺、或者进程终止、或者进程回退。


### 内存
+ 1Byte=8bit // 一般
+ 1K = 2^10
+ 1M = 2^20
+ 1G = 2^30
+ (相对)逻辑地址/(绝对)物理地址 (从进程开始的位置+相对地址)
+ 绝对装入：编译时确定放到内存那个位置
+ 静态重定位：装入时将相对地址变成绝对地址
+ `动态重定位`：运行时动态装入，允许程序在内存中发生移动，允许分配到不连续存储区域，允许动态申请内存
+ 静态链接： 运行前把目标模块合并成一个完整的可执行文件
+ 装入时动态链接：边装入内存边链接其他模块
+ 运行时动态链接：需要什么模块再去链接什么模块

#### 内存管理
+ 内存分配、回收:连续分配(单一连续分配、固定分区分配、动态分区分配),非连续分配(分页分配、分段分配)
+ 空间扩展：虚拟技术、覆盖技术、交换技术
+ 地址转换：3种装入
+ 内存保护：方法一，设置上下限保护；方法二，重定位寄存器+界地址寄存器(是否越界)

> 覆盖技术：程序大小大于内存时，将程序分段，在覆盖区反复覆盖。(没用了，因为程序员太难了)

> `交换技术`：内存紧张时将`进程换出到外存`，是把进程挂起，而PCB仍然长住内存中的，需要记录在PCB中可以管理。磁盘需要分为文件区和交换区,交换区用连续分配提高IO速度

> 内部碎片：分配给进程却不用。 外部碎片：空闲区太小不能分给任何进程。
>> `紧凑`（Compaction）技术：重新定位进程起始地址，整体移动，抹掉空闲区域。

> 单一连续分配：内存分为系统区和用户区、一道用户程序独占，无外部碎片，有内部碎片(那部分没用上)，可以覆盖技术，不一定需要内存保护。

> 固定分区分配： 用户空间分为固定大小分区，每个分区(可以等大、可以不等大)一道作业。无外部碎片，有内部碎片

> `动态分区分配`：根据装入时动态申请进程需要的大小，记录为空闲分区表或者空闲分区链。分配算法复杂
+ 首次适应算法(First Fit):从低地址找到第一个满足大小的空闲分区分配给进程
+ 最佳适应算法(Best Fit)： 优先使用最小的连续空闲区间，留出大块空白。越来越留出更小的空闲，很多碎片
+ 最坏适应算法(Worst Fit)：优先使用最大的连续空闲区间，那么剩下来的空闲区就不会太小。后面来个大的就必须等待了
+ 邻近适应算法(Next Fit)：类似首次适应，优先使用上次查找位置往后的，找到第一个。减少一些查找时间
> 这些算法显然各有很明显的缺点。

> `分页分配`(Page)技术，是物理分配。系统行为，用户无感知。
+ 将内存分为很多"页框"，（一般）每个4KB 
+ 页有编号
+ 进程也分割为多个4KB来对齐，整页整页的来
+ 页号+页内偏移量：因此他是一维的
+ 页号= 逻辑地址/页面长度，页内偏移量=逻辑地址%页面长度
+ 有个`页表（慢表）`可以查询位置
+ `快表`(TLB,联想寄存器)地址变换.
`局部性原理`：时间局部上可能频繁使用相同地址，空间局部上可能相邻的位置会被频繁访问。
可以用TLB高速缓冲这些局部地址，比内存中的页表快多了，可以用来缓冲命中。先查快表，没命中再查页表
+ `多级页表`。因为页表很大的话本身就占用空间，没必要让整个页表常驻内存。因此可以做成多级，而一般是经常反复使用少量的页，但是增加了访问次数

> `分段分配`(Segment)技术，是逻辑分配。用户可以知道的，可编程的。
+ 每段占据连续空间
+ 段间不需要相邻(而分页需要)
+ 段名是用户定义的，按照逻辑功能划分的段
+ 段的大小不固定
+ 用户编程更加方便，程序可读性更高
+ 编译程序会把段名解释为段号
+ 逻辑地址=段号+段内偏移
+ 段号的位数决定了每个进程最多分几段，段内地址位数决定每个段最大长度
+ 需要一个段表来知道位置

> 分段比分页更容易实现信息的共享和保护。不能修改的代码称为`纯代码`或者`可重入代码`，是可以共享的

> 分页管理不会产生外部碎片，而分段管理会

> `段页式管理`：结合两者


> `虚拟内存`。利用局部性原理把暂时不用的内存换到外存，让用户看起来有很大的内存。实现在离散内存技术上

> `请求分页 管理`
+ 缺页中断，等待从外存换入
+ 管理暂时不用的内存换入外存

> `页面置换算法`：换内外存的页面
+ OPT(最佳置换)：每次淘汰最长时间不会被使用的页面。缺页时未必发生了置换。无法实现，因为操作系统没法预知
+ FIFO(先进先出)：把队头的页面淘汰。导致Belady异常，因为为进程分配物理块增多时，缺页次数反而增大，性能差
+ LRU(Least rencently used, 最近最久没使用)：记录的时从上次访问的时间t，时间最早的可以淘汰。性能好，实现困难，开销大，需要硬件支持
+ CLOCK(NRU， Not Recently Used 时钟置换算法):平衡性能和开销。访问位为0表示最近没用过。扫描相邻位置，找到0就可以置换，可能扫两轮(边扫边置0)，如果都是1的话。
+ 改进时钟算法：(访问位，修改位)。最近没访问也没修改的页面优先换(0,0)， 第二轮 (0,1)，可能扫4轮。

> 页面分配策略
+ 驻留集：分配给某个进程可以常驻的内存物理块。太小的话频繁缺页，太大的话并发不行。
+ 驻留集可以固定分配；可以可变分配，看运行情况
+ 工作集：某段时间内进程实际访问页面集合
+ 局部置换：只能进程自己的物理块可以给他换。全局置换：缺页时可以换空闲的给他。
+ 预调页策略：预测待会要用相邻页面，一次调入若干个页面更加高效，减少磁盘IO。主要是进程首次调入，由程序员指出。
+ 请求调用策略：缺哪页调哪页。IO开销大。
+ `磁盘对换区用来换内存，连续分配`，读写更快。`磁盘文件区`可以采用离散分配，不用那么快。(磁盘分为交换区+文件区)
+ 对换区够大的话可以在进程运行前全部从文件区加载进对换区，加快读写。
+ 对换区不够大，但是不用写，可以直接从文件区取。换出时不用写，直接重新读。
+ UNIX未使用过的页面都在文件区，用过的写到对换区，下次从对换区取了。
+ 抖动现象：进程需要的页面数(工作集)高于分配给他的物理内存块，频繁交换。需要操作系统分析工作集大小







